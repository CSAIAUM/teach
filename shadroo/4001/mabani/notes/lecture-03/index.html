<!DOCTYPE html>
<html>
  <head>
    <head>
  <meta charset="UTF-8">
  <meta http-equiv="content-language" content="en">
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>مبانی برنامه نویسی | Lecture 3: Undirected Graphical Models</title>
  <meta name="description" content="مبانی برنامه نویسی - مهر ۱۴۰۰ 
">

  <link rel="shortcut icon" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/favicon.ico">

  <link type=text/css rel=stylesheet href=https://cdn.jsdelivr.net/gh/rastikerdar/vazir-font@26.0.2/dist/font-face.css>

  <link rel="stylesheet" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/css/main.css">
  <link rel="canonical" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/notes/lecture-03/">

  
  <!-- Load Latex JS -->
  <script src="https://cdn.jsdelivr.net/npm/latex.js@0.11.1/dist/latex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/latex.js@0.11.1/dist/latex.component.js"></script>
  
</head>

    <script src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/js/distillpub/template.v2.js"></script>
    <script src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/js/distillpub/transforms.v2.js"></script>
  </head>

  <d-front-matter>
    <script type="text/json">{
      "title": "Lecture 3: Undirected Graphical Models",
      "description": "An introduction to undirected graphical models",
      "published": "January 23, 2019",
      "lecturers": [
        
        {
          "lecturer": "Eric Xing",
          "lecturerURL": "https://www.cs.cmu.edu/~epxing/"
        }
        
      ],
      "authors": [
        
        {
          "author": "Allan Wang"
        },
        
        {
          "author": "Binghao Deng"
        },
        
        {
          "author": "Weizhao Shao"
        },
        
        {
          "author": "Zhuoran Liu"
        }
        
      ],
      "editors": [
        
        {
          "editor": "Lisa Lee",
          "editorURL": "http://leelisa.com"
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body>

    <header class="site-header">

  <div class="wrapper">

    <span class="site-title">
      <a class="page-link" href="https://csaiaum.github.io/teach/shadroo/4001/mabani/">مبانی برنامه نویسی</a>
    </span>

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <a class="page-link" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/logistics/">قوانین</a>
        <a class="page-link" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/lectures/">جلسات</a>
        <a class="page-link" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/notes/">جزوات</a>
        <a class="page-link" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/calendar/">تقویم</a>
        <a class="page-link" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/homework/">تمرینات</a>
        <a class="page-link" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/project/">پروژه</a>
        <a class="page-link" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/source/">منابع</a>
      </div>
    </nav>

  </div>

</header>



    <div class="page-content">

      <d-title>
        <h1 align='right' dir="rtl" >Lecture 3: Undirected Graphical Models</h1>
        <p align='right' dir="rtl">An introduction to undirected graphical models</p>
      </d-title>

      <d-byline></d-byline>

      <d-article align='right' dir="rtl">
        <h2 id="review">Review</h2>

<p>In addition to the <strong>I-map</strong> concept that was introduced in the last lecture, today’s lecture also includes <strong>minimal I-map</strong>.</p>

<h3 id="minimal-i-maps">Minimal I-maps</h3>
<p>A DAG <script type="math/tex">\mathcal{G}</script> is a <strong>minimal I-map</strong> if it is an I-map for a distribution <script type="math/tex">P</script>, and if the removal of even a single edge from <script type="math/tex">\mathcal{G}</script> renders it not an I-map.</p>

<ul>
  <li>
    <p>A distribution may have several minimal I-maps, each corresponding to a specific node-ordering.</p>
  </li>
  <li>
    <p>The fact that <script type="math/tex">\mathcal{G}</script> is a minimal I-map for <script type="math/tex">P</script> is <strong>far from</strong> a guarantee that <script type="math/tex">\mathcal{G}</script> captures the independence structure in <script type="math/tex">P</script>.</p>
  </li>
</ul>

<h2 id="bayes-ball-algorithm">“Bayes-ball” Algorithm</h2>

<p>“Bayes-ball” algorithm is an algorithm that we can apply to retrieve independences directly from a graphical model. We say <script type="math/tex">X</script> is <strong>d-separated</strong> from <script type="math/tex">Z</script> given <script type="math/tex">Y</script> if we cannot send a ball from any node in <script type="math/tex">X</script> to any node in <script type="math/tex">Z</script>. The conditional probability statement (“given <script type="math/tex">Y</script>”) is represented by shading the node in the graph. Examples of three basic directed graphical structures are shown below.</p>

<figure id="basic-structure" class="l-body">
    <div class="row">
        <div class="col two">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/basic.png" />
        </div>
    </div>
</figure>

<ul>
  <li>
    <p>In (a) and (b), the shaded <script type="math/tex">Y</script> node blocks the ball from going between nodes <script type="math/tex">X</script> and <script type="math/tex">Z</script>. This gives the independence relation that was introduced in the last lecture: <script type="math/tex">X \perp Z \mid Y</script>.</p>
  </li>
  <li>
    <p>(c), also called the “V-structure”, is a special case. Opposite from the first two exmaples, the ball can go between <script type="math/tex">X</script> and <script type="math/tex">Z</script> if the node <script type="math/tex">Y</script> is shaded, and is blocked otherwise. Therefore, the graph on the right yields <script type="math/tex">X \perp Z</script>.</p>
  </li>
</ul>

<p>With these basic structures, we can apply the rules on a DAG. For example, let us try to find whether <script type="math/tex">X_2</script> and <script type="math/tex">X_3</script> are independent given <script type="math/tex">X_1</script> and <script type="math/tex">X_6</script>.</p>

<figure id="bayes-ball-example" class="l-body">
    <div class="row">
        <div class="col two">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/dag.png" />
        </div>
    </div>
</figure>

<p>After shading <script type="math/tex">X_1</script> and <script type="math/tex">X_6</script>, the ball cannot go from <script type="math/tex">X_2</script> to <script type="math/tex">X_3</script> through <script type="math/tex">X_1</script> because it is blocked; however, <script type="math/tex">X_2</script>, <script type="math/tex">X_6</script>, and <script type="math/tex">X_5</script> forms a “V-structure”, so the ball can go along the path <script type="math/tex">X_2</script>, <script type="math/tex">X_6</script>, <script type="math/tex">X_5</script>, <script type="math/tex">X_3</script>. Therefore, the independence statement is invalid.</p>

<h2 id="limits-of-directed-and-undirected-gms">Limits of Directed and Undirected GMs</h2>

<p>From a representational perspective, we aim to find a graph <script type="math/tex">\mathcal{G}</script> that precisely captures the independencies in a given distribution <script type="math/tex">P</script>. This goal of learning GMs motivates the following definition.</p>

<h3 id="perfect-maps">Perfect Maps</h3>

<p>We say that a graph <script type="math/tex">\mathcal{G}</script> is a <strong>perfect map (P-map)</strong> for a set of independencies <script type="math/tex">\mathcal{I}</script> if <script type="math/tex">\mathcal{I}(\mathcal{G}) = \mathcal{I}</script>. We say that <script type="math/tex">\mathcal{G}</script> is a perfect map for <script type="math/tex">P</script> if <script type="math/tex">\mathcal{I}(\mathcal{G}) = \mathcal{I}(P)</script>. That is,
<script type="math/tex">\text{sep}_{\mathcal{G}}(X;Z \vert Y) \iff P \models (X \perp Z \vert Y)</script>.</p>

<ul>
  <li>The P-map of a distribution is unique up to I-equivalence between networks. That is, a distribution P can have many P-maps, but all of them are I-equivalent.</li>
</ul>

<p>Arbitrary distribution <script type="math/tex">P</script>’s, however, do not necessarily attain perfect maps as either undirected or directed GMs. Two such examples are shown below.</p>
<figure id="graph-separation" class="l-body">
  <div class="row">
    <div class="col two">
      <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/graph_venn.png" />
    </div>
  </div>
  <figcaption>
    <strong>A Venn diagram illustration of graphical model families, where D is the family of directed GMs, and U the family of undirected GMs.</strong>
  </figcaption>
</figure>

<figure id="graph-separation" class="l-body">
  <div class="row">
    <div class="col two">
      <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/graph_counterexamples.png" />
    </div>
  </div>
</figure>
<p><strong>Left</strong>: A distribution with no possible DGM representation, which entails <script type="math/tex">A\perp C\vert \{B,D\}</script> and <script type="math/tex">B\perp D\vert \{A,C\}</script>. <strong>Right</strong>: The v-structure is a distribution with no UGM representation.</p>

<h2 id="undirected-graphical-models---overview">Undirected Graphical Models - Overview</h2>

<ul>
  <li>There can only be symmetric relationships between a pair of nodes (random variables). In other words, there is no causal effect from one random variable to another.</li>
  <li>The model can represent properties and configurations of a distribution, but it cannot generate samples explicitly.</li>
  <li>Each node has strong correlations with its neighbors.</li>
</ul>

<h3 id="example">Example</h3>

<figure id="UGM-example" class="l-body">
    <div class="row">
        <div class="col two">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/UGM_example.png" />
        </div>
    </div>
</figure>

<p>Let each node represents an image patch. It is impossible to tell what is inside this image patch by isolating it from others. However, when we look at its neighboring image patches, we can see that it’s an image patch of water. Due to the fact that the relationships between neighboring image patches should be symmetric, an image is best represented by an undirected graphical model. This particular undirected graphical model is also known as the grid model.</p>

<h2 id="quantitative-specification">Quantitative Specification</h2>
<h3 id="cliques">Cliques</h3>
<ul>
  <li>Cliques are subgraphs that are fully connected.</li>
  <li>A maximal clique is a clique such that any superset (any bigger subgraph that contains this subgraph) is not a complete graph.</li>
  <li>A sub-clique is a not-necessarily-maximal clique.
    <h4 id="example-1">Example</h4>
  </li>
</ul>
<figure id="clique-example" class="l-body">
    <div class="row">
        <div class="col one">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/clique_example.PNG" />
        </div>
    </div>
</figure>
<figure id="clique-example" class="l-body">
    <div class="row">
        <div class="col two">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/clique_example_max_clique.PNG" />
        </div>
    </div>
</figure>
<figure id="clique-example" class="l-body">
    <div class="row">
        <div class="col two">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/clique_example_sub_clique.PNG" />
        </div>
    </div>
</figure>

<h3 id="potential-functions">Potential Functions</h3>
<p>Each clique can be associated with a <strong>potential function</strong> <script type="math/tex">\psi</script>, which can be understood as a provisional function of its arguments that assigns a pre-probabilistic score of their joint distribution. This potential function can be somewhat arbitrary, but must be non-negative.</p>

<p>Why cliques? Each component of the clique contributes to the overall potential function.</p>
<h4 id="example-2">Example</h4>
<figure id="potential-example" class="l-body">
    <div class="row">
        <div class="col one">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/potential_func_example.PNG" />
        </div>
    </div>
    <figcaption>
    <strong>An example used to illustrate potential functions. Both X1 and X2 are binary.</strong>
    </figcaption>
</figure>
<p>For <script type="math/tex">\psi_c(X_1, X_2)</script>,</p>
<figure id="potential-example" class="l-body">
    <div class="row">
        <div class="col one">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/potential_func_table.PNG" />
        </div>
    </div>
    <figcaption>
    <strong>This table represents the potential function values given combinations of random variable inputs.</strong>
    </figcaption>
</figure>

<p>Potential functions are not necessarily probabilistic:</p>
<figure id="potential-example" class="l-body">
    <div class="row">
        <div class="col one">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/potential_func_illustration.PNG" />
        </div>
    </div>
    <figcaption>
    <strong>Another example used to illustrate potential functions.</strong>
    </figcaption>
</figure>
<p>This model implies that <script type="math/tex">X \perp Z | Y</script>. This independence statement implies (by definition) that the joint must factorize as:</p>
<d-math block="">
\begin{aligned}
    p(x,y,z)&amp;=p(y)p(x|y)p(z|y) \\
    &amp;=p(x,y)p(z|y) \\
    &amp;=p(x|y)p(y,z)
\end{aligned}
</d-math>
<p>Probability distributions can be used as potential functions. However, in this case, we cannot let all potentials be either marginal probabilities or conditional probabilities. So the potential function for this graph cannot be probability distributions.</p>

<h3 id="gibbs-distribution-and-undirected-graphical-model-definition">Gibbs Distribution and Undirected Graphical Model Definition</h3>
<p>Given an undirected graph <script type="math/tex">H</script> and clique potentials functions <script type="math/tex">\psi_C</script> associated with cliques of <script type="math/tex">H</script>, we say <script type="math/tex">P(X_1, ..., X_n)</script> is a <strong>Gibbs distribution</strong> over <script type="math/tex">H</script> if it can be represented as</p>

<script type="math/tex; mode=display">P(X_1, ..., X_n)=\frac{1}{Z}\prod_{c\in C}{\psi_c(\bold{x_c})}</script>

<p>where <script type="math/tex">Z</script> is also known as the partition function. Upper case <script type="math/tex">C</script> denotes the set of all cliques, and lower case <script type="math/tex">c</script> denotes a clique associated with a set of random variables <script type="math/tex">\bold{x}</script>.</p>

<p>An <strong>undirected graphical model</strong> represents a distribution <script type="math/tex">P(X_1, ..., X_n)</script> defined by an undirected graph <script type="math/tex">H</script>, a set of positive potential functions <script type="math/tex">\psi_C</script> and the associated cliques of <script type="math/tex">H</script>, such that</p>
<d-math block="">
\begin{aligned}
P(X_1,...,X_n)=\frac{1}{Z}\prod_{c\in C}{\psi_c(\bold{x_c})} \\
Z=\sum_{x_1,...,x_n}\prod_{c\in C}{\psi_c(\bold{x_c})}
\end{aligned}
</d-math>
<p>Note that this distribution is the Gibbs distribution.</p>

<h3 id="example-ugm-models-depending-on-the-question-of-interest-different-representations-may-be-more-appropriate">Example UGM Models <d-footnote>Depending on the question of interest, different representations may be more appropriate.</d-footnote></h3>
<figure id="UGM-clique-example" class="l-body">
    <div class="row">
        <div class="col one">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/UGM_clique_example.PNG" />
        </div>
    </div>
  <figcaption>
    <strong>An example graph used to illustrate UGM.</strong>
    </figcaption>
</figure>
<h4 id="using-max-cliques">Using Max Cliques</h4>
<figure id="UGM-clique-example" class="l-body">
    <div class="row">
        <div class="col one">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/UGM_clique_example_max_clique.PNG" />
        </div>
    </div>
</figure>
<d-math block="">
\begin{aligned}
  P'(A,B,C,D)=\frac{1}{Z}\psi_c(A,B,D)\psi_c(B,C,D) \\
  Z=\sum_{A,B,C,D}\psi_c(A,B,D)\psi_c(B,C,D)
\end{aligned}
</d-math>
<p>We only need to represent discrete nodes with two 3D tables instead of one 4D table.</p>
<h4 id="using-pairwise-cliques">Using Pairwise Cliques</h4>
<figure id="UGM-clique-example" class="l-body">
    <div class="row">
        <div class="col one">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/UGM_clique_example_sub_clique.PNG" />
        </div>
    </div>
</figure>
<d-math block="">
\begin{aligned}
  P''(A,B,C,D)=\frac{1}{Z}\psi_c(A,B)\psi_c(A,D)\psi_c(B,C)\psi_c(B,D)\psi_c(C,D) \\
  Z=\sum_{A,B,C,D}\psi_c(A,B)\psi_c(A,D)\psi_c(B,C)\psi_c(B,D)\psi_c(C,D)
\end{aligned}
</d-math>
<p>We only need to represent discrete nodes with five 2D tables instead of one 4D table.</p>
<h4 id="using-canonical-representation">Using Canonical Representation</h4>
<p>Even if we use fine-grained representation, the Markov network is often overparameterized. For any given distribution, there are multiple choices of parameters to describe in the model. As shown above, we can either choose max cliques or pairwise cliques to represent this model. Furthermore, ambiguities can arise in clique structures. For example, given a pair of cliques <script type="math/tex">\{A, B\}</script> and <script type="math/tex">\{B, C\}</script>, the information about <script type="math/tex">B</script> can be placed in either of the two cliques, resulting in many ways to specify the samme distribution.</p>

<p>The canonical representation provides a natural approach to avoid this problem. It is defined over all non-empty cliques as shown below.<d-footnote>Please refer to Koller and Friedman Texbook Ch.4, page 129 for details.</d-footnote> The formula performs an inclusion-exclusion computation to make sure that each random variable contributes exactly once to the overall function.</p>
<d-math block="">
\begin{aligned}
    P'''(A,B,C,D)&amp;=\frac{1}{Z}\psi_c(A,B,D)\psi_c(B,C,D) \\
    &amp; \times\psi_c(A,B)\psi_c(A,D)\psi_c(B,C)\psi_c(B,D)\psi_c(C,D) \\
    &amp; \times\psi_c(A)\psi_c(B)\psi_c(C)\psi_c(D)
\end{aligned}
</d-math>
<d-math block="">
\begin{aligned}
    Z&amp;=\sum_{A,B,C,D}\psi_c(A,B,D)\psi_c(B,C,D) \\
    &amp; \times\psi_c(A,B)\psi_c(A,D)\psi_c(B,C)\psi_c(B,D)\psi_c(C,D) \\
    &amp; \times\psi_c(A)\psi_c(B)\psi_c(C)\psi_c(D)
\end{aligned}
</d-math>

<h2 id="qualitative-specification">Qualitative Specification</h2>
<h3 id="global-markov-independency">Global Markov Independency</h3>
<p>Suppose we are given the following UGM, denoted by <script type="math/tex">H</script>:</p>
<figure id="global-markov-example" class="l-body">
    <div class="row">
        <div class="col one">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/global_markov_independence.PNG" />
        </div>
    </div>
</figure>
<p><script type="math/tex">Y</script> separates <script type="math/tex">X</script> and <script type="math/tex">Z</script> if every path from a node in <script type="math/tex">X</script> to a node in <script type="math/tex">Z</script> passes through a node in <script type="math/tex">Y</script>:</p>

<script type="math/tex; mode=display">sep_H(X;Z|Y)</script>

<p>A probability distribution satisfies the <strong>global Markov property</strong> if for any disjoint X,Y,Z such that Y separates X and Z, X is independent of Z given Y.</p>

<script type="math/tex; mode=display">\mathcal{I}(H)=\{X\perp Z | Y:sep_H(X;Z|Y)\}</script>

<h3 id="local-markov-independency">Local Markov Independency</h3>
<p>For each node <script type="math/tex">X_i\in \bold{V}</script>, there is a unique <strong>Markov blanket</strong> of <script type="math/tex">X_i</script>, denoted <script type="math/tex">MB_{X_i}</script>, which is the set of neighbors of <script type="math/tex">X_i</script> in the graph.</p>

<p>The <strong>local Markov independencies</strong> (<script type="math/tex">\mathcal{I}_l</script>) associated with <script type="math/tex">H</script> is:</p>

<script type="math/tex; mode=display">\mathcal{I}_l(H):\{X_i \perp (\bold{V}-\{X_i\}-MB_{X_i})|MB_{X_i}:\forall i\}</script>

<p>In other words, <script type="math/tex">X_i</script> is independent of the rest of the nodes given its immediate neighbors <script type="math/tex">MB_{X_i}</script>.</p>

<h2 id="soundness-and-completeness-of-global-markov-property">Soundness and Completeness of Global Markov Property</h2>

<p>The global Markov property for UGMs is similar to its variant for DGMs, in the sense that they both attain similar soundness and completeness results.</p>

<h3 id="soundness">Soundness</h3>

<p><strong>Theorem</strong>: Let <script type="math/tex">P</script> be a distribution over <script type="math/tex">\mathcal{X}</script>, and <script type="math/tex">\mathcal{G}</script> a Markov network structure over <script type="math/tex">\mathcal{X}</script>. If <script type="math/tex">P</script> is a Gibbs distribution that factorizes over <script type="math/tex">\mathcal{G}</script>, then <script type="math/tex">\mathcal{G}</script> is an I-map for <script type="math/tex">P</script>.</p>

<p><strong>Proof</strong>: Let <script type="math/tex">X,Y,Z</script> be three disjoint subsets in <script type="math/tex">\mathcal{X}</script> such that <script type="math/tex">Z</script> separates <script type="math/tex">X</script> and <script type="math/tex">Y</script> in <script type="math/tex">\mathcal{G}</script>. We will show that <script type="math/tex">P\models (X\perp Y\vert Z)</script>.</p>

<p>First, we observe that there is no direct edge from <script type="math/tex">X</script> to <script type="math/tex">Y</script>. Assuming that <script type="math/tex">(X,Y,Z)</script> is a partition of <script type="math/tex">\mathcal{X}</script>, we know that any clique in <script type="math/tex">\mathcal{G}</script> is fully attained in either <script type="math/tex">X\cup Z</script> or <script type="math/tex">Y\cup Z</script>. Let <script type="math/tex">\mathcal{I}_{X}</script> be the indices of the set of cliques that are contained in <script type="math/tex">X\cup Z</script>, and <script type="math/tex">\mathcal{I}_{Y}</script> be the set defined for <script type="math/tex">Y\cup Z</script>. We know that</p>

<script type="math/tex; mode=display">P(X_1,\cdots,X_n) = \frac{1}{Z}\prod_{i\in \mathcal{I}_X}\phi_i (D_i)\cdot \prod_{i\in \mathcal{I}_Y}\phi_i (D_i).</script>

<p>None of the terms in the first product contains variable from the latter. Hence, we can rewrite this product in the form:</p>

<script type="math/tex; mode=display">P(X_1,\cdots,X_n) = \frac{1}{Z}f(X,Z)g(Y,Z),</script>

<p>and we observe that independence follows.</p>

<p>If <script type="math/tex">X\cup Y\cup Z</script> is a strict subset of <script type="math/tex">\mathcal{X}</script>. Let <script type="math/tex">U = \mathcal{X}\setminus (X\cup Y\cup Z)</script>. We can partition <script type="math/tex">U</script> into two disjoint sets <script type="math/tex">U_1</script> and <script type="math/tex">U_2</script> such that <script type="math/tex">Z</script> separates <script type="math/tex">X\cup U_1</script> from <script type="math/tex">Y\cup U_2</script> in <script type="math/tex">\mathcal{G}</script>. Using our argument from the partition case, we have that <script type="math/tex">\big((X\cup U_1)\perp ((Y\cup U_2)\vert Z</script>. Apply decomposition property of probability we attain that <script type="math/tex">P\models (X\perp Y\vert Z)</script>. <script type="math/tex">\square</script></p>

<h3 id="completeness-hammersley-clifford-theorem">Completeness (Hammersley-Clifford theorem)</h3>

<p><strong>Theorem</strong>: Let <script type="math/tex">P</script> be a positive distribution over <script type="math/tex">\mathcal{X}</script>, and <script type="math/tex">\mathcal{G}</script> a Markov network graph over <script type="math/tex">\mathcal{X}</script>. If <script type="math/tex">\mathcal{G}</script> is an I-map for <script type="math/tex">P</script>, then <script type="math/tex">P</script> is a Gibbs distribution that factorizes over <script type="math/tex">\mathcal{G}</script>.</p>

<p>This result shows that, for positive distributions, the global independencies imply that the distribution factorizes according to the network structure. Thus, for this class of distributions, we have that a distribution $P$ factorizes over a Markov network <script type="math/tex">\mathcal{G}</script> if and only if <script type="math/tex">\mathcal{G}</script> is an I-map for <script type="math/tex">P</script>.</p>

<h2 id="other-markov-properties">Other Markov Properties</h2>

<p>For UGMs, we defined I-maps in terms of global Markov properties. We will now define local independence. Intuitively, when two variables are not directly linked, there must be some way of rendering them conditionally independent. Specifically, we can require that $X$ and $Y$ be independent given all other nodes in the graph.</p>

<h3 id="pairwise-independencies">Pairwise Independencies</h3>

<p>Let <script type="math/tex">\mathcal{G}</script> be a Markov network. We define the pairwise independencies associated with <script type="math/tex">\mathcal{G}</script> to be</p>

<script type="math/tex; mode=display">\mathcal{I}_P(\mathcal{G}) = \{(X\perp Y\vert \mathcal{X}-\{X,Y\}): X-Y\notin \mathcal{G}\}</script>

<figure id="pairwise-indep" class="l-body">
  <div class="row">
    <div class="col two">
      <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/graph_local_example.png" />
    </div>
  </div>
  <figcaption>
    <strong>Example of pairwise independence</strong>
  </figcaption>
</figure>

<p>To illustrate this idea, observe that in the figure above, the variables of interests, <script type="math/tex">A</script> and <script type="math/tex">E</script>, are conditionally independent given all other nodes in the graph, <script type="math/tex">\{B,C,D\}</script>.</p>

<p>Pairwise and local indepdencies are also related. Their relationships are described in the following propositions and theorem.</p>

<h3 id="proposition">Proposition</h3>

<p><strong>1</strong>. For any Markov network <script type="math/tex">\mathcal{G}</script> and any distribution <script type="math/tex">P</script>, we have that if <script type="math/tex">P\models \mathcal{I}_l(\mathcal{G})</script>  then <script type="math/tex">P\models \mathcal{I}_P(\mathcal{G})</script>.</p>

<p><strong>2</strong>. For any Markov network <script type="math/tex">\mathcal{G}</script> and any distribution <script type="math/tex">P</script>, we have that if <script type="math/tex">P\models \mathcal{I}(\mathcal{G})</script> then <script type="math/tex">P\models \mathcal{I}_l(\mathcal{G})</script>.</p>

<p><strong>3</strong>. Let <script type="math/tex">P</script> be a positive distribution. If <script type="math/tex">P</script> satisfies <script type="math/tex">\mathcal{I}_P(\mathcal{G})</script>, then <script type="math/tex">P</script> satisfies <script type="math/tex">\mathcal{I}(\mathcal{G})</script>.</p>

<h3 id="theorem">Theorem</h3>

<p>The followings are equivalent for a positive distribution <script type="math/tex">P</script>:</p>

<h4 id="pmodels-mathcali_lmathcalg"><script type="math/tex">P\models \mathcal{I}_l(\mathcal{G})</script></h4>
<h4 id="pmodels-mathcali_pmathcalg"><script type="math/tex">P\models \mathcal{I}_P(\mathcal{G})</script></h4>
<h4 id="pmodels-mathcalimathcalg"><script type="math/tex">P\models \mathcal{I}(\mathcal{G})</script></h4>

<h2 id="exponential-form">Exponential Form</h2>
<p>Since we don’t want to constraint the clique potentials to be positive in all situations, exponential form is used to represent a clique potential <script type="math/tex">\phi_c(x_c)</script> in an unconstrained form using a real-value “energy” funtion <script type="math/tex">\phi_c(x_c)</script>:</p>

<script type="math/tex; mode=display">\Phi_c(x_c)=\exp\bigg\{-\phi_c(x_c)\bigg\}</script>

<p>This then gives the joint probability a nice additive structure</p>

<script type="math/tex; mode=display">p(x)=\frac{1}{Z}\exp\bigg\{-\sum_{c\in C}\phi_c(x_c)\bigg\}=\frac{1}{Z}\exp\bigg\{-H(x)\bigg\}</script>

<p>where the sum in the exponent is called the “free energy”:</p>

<script type="math/tex; mode=display">H(x) = \sum_{c\in C}\phi_c(x_c)</script>

<p>This form of representation is called the “Boltzmann distribution” in physics, and a log-linear model in statstics.</p>

<h2 id="undirected-graph-exmples">Undirected Graph Exmples</h2>
<p>In this section, we cover several well-known undirected graphical models: Boltzmann Machine (BM), Ising model, Restricted Boltzmann Machine (RBM), and Conditional Random Field (CRF).</p>
<h3 id="boltzmann-machine-bm">Boltzmann Machine (BM)</h3>
<p>Boltzmann Machine is a fully connected graph with pairwise (edge) potentials on binary-valued nodes. One example is shown in the following figure:</p>

<figure class="l-body">
    <div class="row">
        <div class="col one">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/BM.png" />
        </div>
    </div>
</figure>

<p>Its probability distribution can be written as:</p>

<script type="math/tex; mode=display">p(x_1,x_2,x_3,x_4)=\frac{1}{Z}\exp\bigg\{\sum_{ij}\phi_{ij}(x_i,x_j)\bigg\}</script>

<p>It could also be written in a quadratic way:</p>

<script type="math/tex; mode=display">p(x_1,x_2,x_3,x_4)=\frac{1}{Z}\exp\bigg\{\sum_{ij}\theta_{ij}x_ix_j+\sum_i\alpha_ix_i+C\bigg\}</script>

<p>Hence the overall free energy function has the form:</p>

<script type="math/tex; mode=display">H(x)=\sum_{ij}(x_i-\mu)\Theta_{ij}(x_j-\mu)=(x-\mu)^T\Theta(x-\mu)</script>

<p>which can then be solved using quadratic programming.</p>

<h3 id="ising-model">Ising model</h3>
<p>In the Ising model, nodes are arranged in a regular topology (often a regular packing grid) and connected only to their geometric neighbors. It is like a sparse Boltzmann Machine. There is also the multi-state Ising model (also called Potts model), in which nodes can take multiple values instead of just binary values. One example of Ising model is shown in the following figure:</p>

<figure class="l-body">
    <div class="row">
        <div class="col one">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/IS.png" />
        </div>
    </div>
</figure>

<p>Its probability distribution can be written as</p>

<script type="math/tex; mode=display">p(X)=\frac{1}{Z}\exp\bigg\{\sum_{i,j\in N_i}\theta_{ij}X_iX_j+\sum_i \theta_{i0}X_i\bigg\}</script>

<h3 id="restricted-boltzmann-machine-rbm">Restricted Boltzmann Machine (RBM)</h3>
<p>The Restricted Bolzmann Machine is a bipartite graph with connections between one layer of hidden units and one layer of visible units. One example is shown in the following figure:</p>

<figure class="l-body">
    <div class="row">
        <div class="col two">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/RBM.png" />
        </div>
    </div>
</figure>

<p>Its probability distribution can be written as</p>

<script type="math/tex; mode=display">p(x,h|\theta)=\exp\bigg\{\sum_i\theta_i\phi_i(x_i) + \sum_j\theta_j\phi_j(h_j) + \sum_{i,j}\theta_{i,j}\phi_{i,j}(x_i,h_j)-A(\theta)\bigg\}</script>

<p>RBM has some appealing properties. For example, factors are marginally dependent and factors are conditionally independent given observations on the visible nodes. They enable one to use iterative Gibbs sampling for inference and learning on RBM. If the edges in RBM were directed, there would be plenty of V-structures in the graph (lots of dependences) that increase the inference difficulty.</p>

<h3 id="conditional-random-field-crf">Conditional Random Field (CRF)</h3>
<p>Conditional random field is an analogous form of HMM in the undirected case. It allows arbitrary dependencies on the input. For example, when labeling <script type="math/tex">X_i</script>, future observations can be taken into account. An example of CRF is shown in the figure:</p>

<figure class="l-body">
    <div class="row">
        <div class="col one">
            <img src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/img/notes/lecture-03/CRF.png" />
        </div>
    </div>
</figure>

<p>The probability distribution could be written as</p>

<script type="math/tex; mode=display">p_\theta(y|x)=\frac{1}{Z(\theta,x)}\exp\bigg\{\sum_c\theta_cf_c(x,y_c)\bigg\}</script>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">مبانی برنامه نویسی</h2>
    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">گروه کامپیوتر دانشگاه آزاد مشهد</li><li><a class="u-email" href="mailto:csaiaum.ir@gmail.com">csaiaum.ir@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/csaiaum" target="_blank"><i class="fab fa-github"></i> <span class="username">csaiaum</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>&copy; Copyright 2021 Azad Islamic University, Mashhad Branch</p>
      </div>
    </div>

  </div>

</footer>


  </body>

  <d-bibliography src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/bibliography/2019-01-23-lecture-03.bib">
  </d-bibliography>

  <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.js"></script>
<script src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/js/katex.js"></script>



<!-- Load Anchor JS -->
<script src="//cdnjs.cloudflare.com/ajax/libs/anchor-js/3.2.2/anchor.min.js"></script>
<script>
  anchors.options.visible = 'hover';
  anchors.add('article h2, article h3, article h4, article h5, article h6');
</script>



<!-- Adjust LaTeX JS -->
<script src="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/js/latex.js"></script>


<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/https://csaiaum.github.io/teach/shadroo/4001/mabani/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');
</script>


</html>
